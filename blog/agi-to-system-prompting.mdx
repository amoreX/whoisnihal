---
title: the AGI race became a prompting race
description: How the pursuit of artificial general intelligence turned into competitive system prompt engineering
date: 29 January, 2026
---

We were promised AGI. Machines that think. Systems that reason. The next step in intelligence.

What we got instead is a competition to write better system prompts.

## The Great Pivot

Somewhere around 2023-2024, the narrative shifted. Labs stopped talking about "artificial general intelligence" and started talking about "capabilities." The goalposts moved from "machine that can think" to "model that can follow instructions really well."

And honestly? That's not a bad thing. But let's be honest about what happened.

## What AGI Was Supposed To Be

The original vision:

- **General reasoning** - Apply intelligence to novel problems without specific training
- **Transfer learning** - Skills in one domain naturally extend to others  
- **Autonomous goal pursuit** - Set a goal, figure out the steps, execute
- **Self-improvement** - Get better without human intervention
- **Understanding** - Not just pattern matching, but genuine comprehension

This was the dream that launched a thousand research papers.

## What We Actually Built

What we have now:

- **Extremely sophisticated autocomplete** - Predict the next token, scale it up
- **In-context learning** - Follow examples in the prompt
- **Instruction following** - Do what the system prompt says
- **Tool use** - Call APIs when prompted to

These are genuinely impressive. But they're not AGI.

## The System Prompt Wars

Here's where it gets interesting. The differentiator between AI products isn't the model anymore. It's the system prompt.

Same base model. Different prompt. Completely different product.

Claude, GPT-4, Gemini - they're all running on similar architectures. The magic is in:

```
You are a helpful assistant that...
```

That's it. That's the moat.

### The Prompt Engineering Industrial Complex

A new discipline emerged:

- **Prompt engineers** making six figures to write instructions
- **System prompt libraries** being treated as trade secrets
- **A/B testing** prompts like landing pages
- **Prompt injection attacks** as a security category
- **Jailbreaking** as a competitive sport

We didn't build thinking machines. We built really good instruction followers. And now we're competing on who can write the best instructions.

## The Capability Illusion

Modern LLMs create an illusion of intelligence that's easy to mistake for the real thing:

**They can code** - But they're pattern-matching from training data, not understanding algorithms

**They can reason** - But chain-of-thought is more "show your work" theater than actual reasoning

**They can learn in-context** - But they forget everything when the context window ends

**They can use tools** - But only tools they're explicitly told about in the prompt

Every impressive demo is carefully prompted. The system prompt is doing the heavy lifting.

## Why This Happened

The pivot makes sense when you understand the economics:

1. **Scaling laws worked** - More compute = better performance. Keep scaling.
2. **RLHF worked** - Fine-tune on human preferences. Make it useful.
3. **Products shipped** - ChatGPT proved you could monetize this.
4. **AGI is hard** - True reasoning is unsolved. Prompting is a workaround.

The path of least resistance was clear: stop trying to solve general intelligence, start making really good chatbots.

## The Uncomfortable Truth

Here's what nobody wants to admit:

**We don't know how to build AGI.** Scaling alone won't get us there. Neither will better prompts. We're missing something fundamental about how reasoning actually works.

**Current AI is deeply brittle.** Change the prompt slightly and watch the model break. That's not intelligence - that's sensitivity to input formatting.

**The benchmarks are gamed.** Models are trained to perform on benchmarks. When the test becomes the training objective, the metric stops measuring what we care about.

## What This Means For Builders

If you're building with AI:

1. **The prompt IS your product** - Invest in it accordingly
2. **Don't assume intelligence** - Your model is following instructions, not thinking
3. **Build for failure modes** - Every edge case is a prompt failure
4. **Stay model-agnostic** - Today's best model is tomorrow's commodity

## The Path to Real AGI

What might actually move the needle:

- **New architectures** - Transformers might not be the final answer
- **World models** - Systems that understand cause and effect
- **Active learning** - Models that seek out information they need
- **Compositional reasoning** - Building complex thoughts from simple primitives

But these are research problems, not prompt engineering problems.

## Closing Thoughts

The AGI race became a prompting race because prompting works well enough for products. And products make money.

That's not cynical - it's practical. We build with the tools we have.

But let's stop pretending that better system prompts are steps toward AGI. They're steps toward better chatbots. And that's fine. Chatbots are useful.

Just don't confuse utility with intelligence.

The machines aren't thinking yet. They're just really good at following instructions.

And the humans writing those instructions? They're the real intelligence in the system.

At least for now.
